<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
  <head>
    <link rel=stylesheet type="text/css" href="style.css">
    <title>Robert Kooima</title>
  </head>
  <body>

    <h1><a href="index.html">Robert Kooima</a></h1>

    <table id="nav">
      <tr>
        <td><h3><a href="courses.html">Courses</a></h3></td>
        <td><h3><a href="research.html">Research</a></h3></td>
        <td><h3><a href="talks.html">Talks</a></h3></td>
        <td><h3><a href="applications.html">Applications</a></h3></td>
        <td><h3><a href="installations.html">Installations</a></h3></td>
        <td><h3><a href="code.html">Code</a></h3></td>
        <td><h3><a href="misc.html">Misc.</a></h3></td>
      </tr>
    </table>

    <div class="item">
      <div class="pic">
        <img alt="orbiter" src="images/orbiter.jpg" width="320" height="180">
      </div>
      <div class="txt">
        <h3><a name="orbiter">Orbiter: Moonwall Mk II</a></h3>
        <p><em>Spring 2012</em></p>
        <p>The original <a href="installations.html#moonwall-adler">Moonwall</a> installation used the <a href="#tellurion">Tellurion</a> renderer. In 2012 a new Moonwall implementation, based on the <a href="#panoview">Panoview</a> renderer, was created. This new renderer allows for significantly larger data sets to be displayed with increased efficiency. A YouTube video titled <a href="http://www.youtube.com/watch?v=OPJDxEkmjJo">&ldquo;LRO and the Real-time 3D Moon&rdquo;</a> demonstrates its capabilities. Another video, <a href="http://www.youtube.com/watch?v=Km9_RMPdwR8">&ldquo;A Lazy Orbit of the Moon&rdquo;<a> utilizes this technology to provide a relaxing look at the moon in close-up.</p>
      </div>
    </div>

    <div class="item">
      <div class="pic">
        <img alt="panoview" src="images/panoview.jpg" width="320" height="240">
      </div>
      <div class="txt">
        <h3><a name="panoview">Stereoscopic Spherical Panorama Rendering</a></h3>
        <p><em>Fall 2011</em></p>
        <p>In 2011 I developed an improved set of image processing tools and caching algorithms for efficiently managing and displaying very high resolution stereoscopic spherical panoramas. <a href="http://youtu.be/5dTpLCXRCfA">This YouTube video</a> demonstrates the technology. This work was demonstrated at <a href="http://www.cinegrid.org/">Cinegrid 2011</a> and <a href="http://sc11.supercomputing.org/">SC 2011</a>. In <a href="http://www.youtube.com/watch?v=0Gi2qZltdtc">this YouTube video</a> (image at the left) Dan Sandin visits the <a href="panorama/index.html#bluebonnet-3">Bluebonnet Swamp</a> using the <a href="http://ivl.calit2.net/wiki/index.php/Infrastructure">Calit2 StarCAVE</a>.</p>
      </div>
    </div>

    <div class="item">
      <div class="pic">
        <img alt="panorama" src="images/panorama.jpg" width="320" height="240">
      </div>
      <div class="txt">
        <h3><a name="panorama" href="panorama/index.html">Stereoscopic Spherical Panorama Capture</a></h3>
        <p><em>Fall 2011</em></p>
        <p>In support of my work in high-performance large-scale <a href="#panoview">spherical data rendering</a>, I've acquired a <a href="http://gigapan.org/cms/shop/epic-pro">GigaPan EPIC Pro</a> and a stereoscopic camera system developed by <a href="http://www.qwerty.com/Environmental_Imaging/Index.html">Dick Ainsworth</a>. With these, I've captured a number of stereoscopic spherical panoramas at sites around Louisiana. Here is a <a href="panorama/index.html">catalog of these images</a>, with full-resolution downloads.</p>
      </div>
    </div>

    <div class="item">
      <div class="pic">
        <img alt="REVE" src="images/reve.jpg" width="320" height="167">
      </div>
      <div class="txt">
        <h3><a name="multiautovr" href="pdfs/Kooima-VRST2010.pdf">A Multi-viewer Tiled Autostereoscopic Virtual Reality Display</a></h3>
        <p><em>2010</em></p>
        <p><a href="pdfs/Kooima-VRST2010.pdf">This paper</a> documents the development of the <a href="interleaver/interleaver.html">Autostereo Interleaver</a> and its application to a large-scale multi-user autostereoscopic display. The primary contributions of this work include the use of linescreen shift to &ldquo;synchronize&rdquo; the lenticulars of a large number of autostereo displays, causing them to behave in concert as a single large display, and the application of user tracking to mitigate some of the issues in autostereo display. This work was presented at <a href="talks.html#vrst2010">ACM VRST 2010 in Hong Kong.</a> The image to the left shows the <a href="http://ivl.calit2.net/wiki/index.php/Infrastructure">KAUST REVE</a>, described in <a href="http://www.evl.uic.edu/files/pdf/future.pdf">this article</a> on the future of the CAVE.</p>
      </div>
    </div>

    <div class="item">
      <div class="pic">
        <img alt="Real-time Digital Dome Rendering Techniques and Technologies" src="images/adler-ips2008-paper.png" width="320" height="240">
      </div>
      <div class="txt">
        <h3><a name="real-time-dome" href="pdfs/real-time-dome.pdf">Real-time Digital Dome Rendering Techniques and Technologies</a></h3>
        <p><em>1 July 2008</em></p>
        <p><a href="pdfs/real-time-dome.pdf">This paper</a> enumerates several GPU-accelerated approaches to the problem of real-time 3D rendering using multi-projector edge-blended digital dome displays. A variety of spherical correction approaches are described, organized in terms of the GPU capability that each exploits. This paper emerged from work performed with the staff of the <a href="http://www.adlerplanetarium.org/svl/index.shtml">Space Visualization Laboratory</a> at the Adler Planetarium, using <a href="http://www.adlerplanetarium.org/exhibits/starrider.shtml">Adler's Definiti Space Theater</a>. This paper was presented at the <a href="talks.html#adler-ips2008">2008 meeting of the International Planetarium Society</a>.</p>
      </div>
    </div>

    <div class="item">
      <div class="pic">
        <img alt="Tellurion" src="images/thumb.jpg" width="320" height="240">
      </div>
      <div class="txt">
        <h3><a name="tellurion">Tellurion</a></h3>
        <p><em>2007&mdash;present</em></p>
        <p>Tellurion implements a highly-scalable real-time planetary terrain composition algorithm. A GPGPU process tessellates terrain geometry in real time, and transitions smoothly from planet scale down to sub-meter resolution. Tellurion enables the investigation of a class of generalized terrain composition operators that merge data of widely disparate resolution, projection, and coverage on the fly. These composition operations are uniformly applicable to both terrain height maps and surface maps. The cluster-parallel renderer is supported by a multi-threaded data paging mechanism that performs view-dependant loading of data sources of arbitrary size. The system has been demonstrated displaying 115GB of data in real time, including height data covering the U.S. at a resolution of 30 meters. See the <a href="installations.html">installations page</a> for a listing of several showings. Tellurion was my Ph.D. work. See my dissertation, <a href="pdfs/Kooima-Dissertation.pdf">Planetary-scale Terrain Composition</a>, for detailed coverage or <a href="http://www.youtube.com/user/evltube?blend=3&ob=5#p/u/15/BVHRNYOUzcA">this YouTube video</a> for an overview. I successfully <a href="talks.html#defense"> defended on October 23, 2008</a>, and a paper summarizing the technology was subsequently published in <a href="http://www.computer.org/portal/web/csdl/doi/10.1109/TVCG.2009.43">IEEE Transactions on Visualization &amp; Computer Graphics</a>.</p>
      </div>
    </div>

    <div class="item">
      <div class="pic">
        <img alt="A GPU Sub-pixel Algorithm for Autostereoscopic Virtual Reality" src="images/varrier-combiner.png" width="320" height="240">
      </div>
      <div class="txt">
        <h3><a name="combiner" href="pdfs/Kooima-VR07.pdf">A GPU Sub-pixel Algorithm for Autostereoscopic Virtual Reality</a></h3>
        <p><em>Spring 2007</em></p>
        <p>The Varrier Combiner is a GPU-based algorithm performing real-time autostereoscopic sub-pixel spatial multiplexing. Such an algorithm is necessary for the correct function of parallax barrier displays such as the <a href="research.html#varrier">Varrier</a>. Prior to this work, autostereo interleaving was a very expensive process which placed a heavy performance burden upon all autostereo applications. By expressing the problem in terms of GLSL vertex and pixel shading, the computational expense is moved to the GPU, which eliminates the performance degradation completely. <a href="pdfs/Kooima-VR07.pdf">Varrier Combiner</a> was presented at IEEE VR 07 and published in the conference proceedings. A <a href="varrier_combiner/varrier_combiner.html">C module</a> implementing the algorithm may be used to port OpenGL applications to the Varrier.</p>
      </div>
    </div>

    <div class="item">
      <div class="pic">
        <img alt="Varrier" src="images/varrier.jpg" width="320" height="240">
      </div>
      <div class="txt">
        <h3><a name="varrier">Varrier</a></h3>
        <p><em>Spring 2005&mdash;2010</em></p>
        <p>The Varrier autostereoscopic virtual reality system is a high-resolution, real-time, parallax-barrier 3D display. It enables stereoscopic viewing without the need for 3D glasses. The Varrier project was started by EVL co-founder <a href="http://www.evl.uic.edu/dan/">Dan Sandin</a> in 2001 and included EVL graduate students <a href="http://www.evl.uic.edu/core.php?mod=4&amp;type=5&amp;indi=2">Todd Margolis</a>, <a href="http://www.evl.uic.edu/core.php?mod=4&amp;type=5&amp;indi=235">Tom Peterka</a>, <a href="http://www.evl.uic.edu/core.php?mod=4&amp;type=5&amp;indi=191">Jinghua Ge</a>, <a href="http://www.evl.uic.edu/core.php?mod=4&amp;type=5&amp;indi=46">Javier Girado</a>, and <a href="http://www.evl.uic.edu/core.php?mod=4&amp;type=5&amp;indi=260">myself</a>. We designed and built a <a href="http://www.evl.uic.edu/core.php?mod=4&amp;type=1&amp;indi=275">35-panel</a> display, a <a href="http://www.evl.uic.edu/core.php?mod=4&amp;type=4&amp;indi=449">65-panel</a> display, a 6-panel display, two <a href="http://www.evl.uic.edu/core.php?mod=4&amp;type=1&amp;indi=290">Personal Varrier</a> displays, and a 2-panel Personal Varrier. This technology has produced a <a href="http://www.evl.uic.edu/files/pdf/Siggraph2005.pdf">SIGGRAPH paper</a>, an <a href="pdfs/Kooima-VR07.pdf">IEEE VR paper</a>, and a <a href="http://www.evl.uic.edu/files/pdf/Varrier_SPIE_07.pdf">SPIE paper</a> summarizing the results over the history of the project. The system is described in <a href="http://www.youtube.com/watch?v=g7jW1bKLRXU">this YouTube video</a>.</p>
      </div>
    </div>

    <hr>
    <p style="text-align:right"><i>kooima&#64;csc&#46;lsu&#46;edu</i></p>
  </body>
</html>
